{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on LLY event\n",
    "\n",
    "Sentiment analysis on the Eli Lilly free insulin event on 11 November 2022, with a dataset from Mastodon. Using BERT trained with the IMDB training set as sentiment analysis model outputting continuous sentiment scores.\n",
    "\n",
    "Written by Luc Bijl."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Mastodon dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../datasets/mastodon-lly.pkl','rb') as file:\n",
    "    mastodon_dataframes = pickle.load(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis of the topic: Lilly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataset with toots related to the topics 'Lilly', 'Eli Lilly', 'Eli Lilly and company' and 'LLY'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-08 14:42:58</th>\n",
       "      <td>109478581359363509</td>\n",
       "      <td>&lt;p&gt;ICYMI yesterday, our new &lt;a href=\"https://n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-05 17:58:35</th>\n",
       "      <td>109462365059484871</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01 20:33:41</th>\n",
       "      <td>109440324430339788</td>\n",
       "      <td>&lt;p&gt;Sophia has nursery toys Charlie and Lilly f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 18:53:33</th>\n",
       "      <td>109434268151114981</td>\n",
       "      <td>&lt;p&gt;Eli Lilly CEO says insulin tweet flap “prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28 03:01:05</th>\n",
       "      <td>109419198231109803</td>\n",
       "      <td>&lt;p&gt;Tickets acquired to see The Mountain Goats ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-08 14:42:58  109478581359363509   \n",
       "2022-12-05 17:58:35  109462365059484871   \n",
       "2022-12-01 20:33:41  109440324430339788   \n",
       "2022-11-30 18:53:33  109434268151114981   \n",
       "2022-11-28 03:01:05  109419198231109803   \n",
       "\n",
       "                                                               Content  \n",
       "Date                                                                    \n",
       "2022-12-08 14:42:58  <p>ICYMI yesterday, our new <a href=\"https://n...  \n",
       "2022-12-05 17:58:35  <p><span class=\"h-card\"><a href=\"https://roman...  \n",
       "2022-12-01 20:33:41  <p>Sophia has nursery toys Charlie and Lilly f...  \n",
       "2022-11-30 18:53:33  <p>Eli Lilly CEO says insulin tweet flap “prob...  \n",
       "2022-11-28 03:01:05  <p>Tickets acquired to see The Mountain Goats ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_lilly = pd.DataFrame(columns=['Date','ID','Content'])\n",
    "lilly_topics = ['Lilly', 'Eli Lilly', 'Eli Lilly and company', 'LLY']\n",
    "\n",
    "for topic in lilly_topics:\n",
    "    df_lilly = pd.concat([df_lilly,mastodon_dataframes[topic]])\n",
    "\n",
    "df_lilly.drop_duplicates(subset='ID',keep='first',inplace=True)\n",
    "df_lilly = df_lilly.set_index('Date')\n",
    "\n",
    "df_lilly.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_lilly)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>ICYMI yesterday, our new <a href=\"https://newsie.social/tags/cardiovascular\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>cardiovascular</span></a> reporter Elaine Chen reporting on the intersection of <a href=\"https://newsie.social/tags/obesity\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>obesity</span></a> and <a href=\"https://newsie.social/tags/diabetes\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>diabetes</span></a>: </p><p>the effects of constricting a drug for one condition that\\'s prescribed off-label for another</p><p><a href=\"https://www.statnews.com/2022/12/07/eli-lilly-tightens-access-tirzepatide-mounjaro-diabetes-obesity/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">statnews.com/2022/12/07/eli-li</span><span class=\"invisible\">lly-tightens-access-tirzepatide-mounjaro-diabetes-obesity/</span></a></p>'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lilly['Content'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that cleans the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ICYMI yesterday, our new cardiovascular reporter Elaine Chen reporting on the intersection of obesity and diabetes: the effects of constricting a drug for one condition that's prescribed off-label for another\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[#@]', '', text)\n",
    "    return text\n",
    "\n",
    "df_lilly['Text'] = df_lilly['Content'].apply(clean_text)\n",
    "\n",
    "df_lilly['Text'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the cleaned text to the language BERT can interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "lilly_encodings = tokenizer(df_lilly['Text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "lilly = torch.utils.data.TensorDataset(lilly_encodings['input_ids'], lilly_encodings['attention_mask'])\n",
    "lilly_dataloader = DataLoader(lilly, batch_size=16, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading BERT that is trained on the normalized IMDB dataset from Stanford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = torch.load('bert-imdb.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BERT to perform sentiment analysis on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Text</th>\n",
       "      <th>BERT sentiment score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-08 14:42:58</th>\n",
       "      <td>109478581359363509</td>\n",
       "      <td>&lt;p&gt;ICYMI yesterday, our new &lt;a href=\"https://n...</td>\n",
       "      <td>ICYMI yesterday, our new cardiovascular report...</td>\n",
       "      <td>0.339886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-05 17:58:35</th>\n",
       "      <td>109462365059484871</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://roman...</td>\n",
       "      <td>skimgoth and water lillies?</td>\n",
       "      <td>0.025848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01 20:33:41</th>\n",
       "      <td>109440324430339788</td>\n",
       "      <td>&lt;p&gt;Sophia has nursery toys Charlie and Lilly f...</td>\n",
       "      <td>Sophia has nursery toys Charlie and Lilly for ...</td>\n",
       "      <td>0.354358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 18:53:33</th>\n",
       "      <td>109434268151114981</td>\n",
       "      <td>&lt;p&gt;Eli Lilly CEO says insulin tweet flap “prob...</td>\n",
       "      <td>Eli Lilly CEO says insulin tweet flap “probabl...</td>\n",
       "      <td>-0.059616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28 03:01:05</th>\n",
       "      <td>109419198231109803</td>\n",
       "      <td>&lt;p&gt;Tickets acquired to see The Mountain Goats ...</td>\n",
       "      <td>Tickets acquired to see The Mountain Goats and...</td>\n",
       "      <td>0.588035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-08 14:42:58  109478581359363509   \n",
       "2022-12-05 17:58:35  109462365059484871   \n",
       "2022-12-01 20:33:41  109440324430339788   \n",
       "2022-11-30 18:53:33  109434268151114981   \n",
       "2022-11-28 03:01:05  109419198231109803   \n",
       "\n",
       "                                                               Content  \\\n",
       "Date                                                                     \n",
       "2022-12-08 14:42:58  <p>ICYMI yesterday, our new <a href=\"https://n...   \n",
       "2022-12-05 17:58:35  <p><span class=\"h-card\"><a href=\"https://roman...   \n",
       "2022-12-01 20:33:41  <p>Sophia has nursery toys Charlie and Lilly f...   \n",
       "2022-11-30 18:53:33  <p>Eli Lilly CEO says insulin tweet flap “prob...   \n",
       "2022-11-28 03:01:05  <p>Tickets acquired to see The Mountain Goats ...   \n",
       "\n",
       "                                                                  Text  \\\n",
       "Date                                                                     \n",
       "2022-12-08 14:42:58  ICYMI yesterday, our new cardiovascular report...   \n",
       "2022-12-05 17:58:35                        skimgoth and water lillies?   \n",
       "2022-12-01 20:33:41  Sophia has nursery toys Charlie and Lilly for ...   \n",
       "2022-11-30 18:53:33  Eli Lilly CEO says insulin tweet flap “probabl...   \n",
       "2022-11-28 03:01:05  Tickets acquired to see The Mountain Goats and...   \n",
       "\n",
       "                     BERT sentiment score  \n",
       "Date                                       \n",
       "2022-12-08 14:42:58              0.339886  \n",
       "2022-12-05 17:58:35              0.025848  \n",
       "2022-12-01 20:33:41              0.354358  \n",
       "2022-11-30 18:53:33             -0.059616  \n",
       "2022-11-28 03:01:05              0.588035  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "list_predicted_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in lilly_dataloader:\n",
    "        input_ids, attention_mask = batch\n",
    "        output = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predicted_scores = output.logits.view(-1)\n",
    "\n",
    "        list_predicted_scores.extend(predicted_scores.tolist())\n",
    "\n",
    "df_lilly['BERT sentiment score'] = list_predicted_scores\n",
    "\n",
    "df_lilly.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../datasets/bert-scored/lilly.pkl', 'wb') as file:\n",
    "    pickle.dump(df_lilly, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis of the topic: Insulin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataset with toots related to the topic 'Insulin'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-09 20:09:41</th>\n",
       "      <td>109485528680726575</td>\n",
       "      <td>&lt;p&gt;Henceforth my insulin pump shall be known a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 14:52:21</th>\n",
       "      <td>109484280827598555</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 10:31:24</th>\n",
       "      <td>109483255136181443</td>\n",
       "      <td>&lt;p&gt;fri/20221209&lt;/p&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 06:23:15</th>\n",
       "      <td>109482278888205908</td>\n",
       "      <td>&lt;p&gt;Being an insulin-injecting diabetic means o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-08 23:16:32</th>\n",
       "      <td>109480601078091132</td>\n",
       "      <td>&lt;p&gt;I am now part cyborg and have sent my first...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-09 20:09:41  109485528680726575   \n",
       "2022-12-09 14:52:21  109484280827598555   \n",
       "2022-12-09 10:31:24  109483255136181443   \n",
       "2022-12-09 06:23:15  109482278888205908   \n",
       "2022-12-08 23:16:32  109480601078091132   \n",
       "\n",
       "                                                               Content  \n",
       "Date                                                                    \n",
       "2022-12-09 20:09:41  <p>Henceforth my insulin pump shall be known a...  \n",
       "2022-12-09 14:52:21                                                     \n",
       "2022-12-09 10:31:24                                <p>fri/20221209</p>  \n",
       "2022-12-09 06:23:15  <p>Being an insulin-injecting diabetic means o...  \n",
       "2022-12-08 23:16:32  <p>I am now part cyborg and have sent my first...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_insulin = mastodon_dataframes['Insulin']\n",
    "df_insulin = df_insulin.set_index('Date')\n",
    "\n",
    "df_insulin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_insulin)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>Henceforth my insulin pump shall be known as H.E.R.B.I.E. <a href=\"https://social.parentheticalrecluse.com/tags/t1d\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>t1d</span></a></p>'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_insulin['Content'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Henceforth my insulin pump shall be known as H.E.R.B.I.E. t1d'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[#@]', '', text)\n",
    "    return text\n",
    "\n",
    "df_insulin['Text'] = df_insulin['Content'].apply(clean_text)\n",
    "\n",
    "df_insulin['Text'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the cleaned text to the language BERT can interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "insulin_encodings = tokenizer(df_insulin['Text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "insulin = torch.utils.data.TensorDataset(insulin_encodings['input_ids'], insulin_encodings['attention_mask'])\n",
    "insulin_dataloader = DataLoader(insulin, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading BERT that is trained on the normalized IMDB dataset from Stanford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = torch.load('bert-imdb.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BERT to perform sentiment analysis on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Text</th>\n",
       "      <th>BERT sentiment score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-09 20:09:41</th>\n",
       "      <td>109485528680726575</td>\n",
       "      <td>&lt;p&gt;Henceforth my insulin pump shall be known a...</td>\n",
       "      <td>Henceforth my insulin pump shall be known as H...</td>\n",
       "      <td>0.184103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 14:52:21</th>\n",
       "      <td>109484280827598555</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.014581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 10:31:24</th>\n",
       "      <td>109483255136181443</td>\n",
       "      <td>&lt;p&gt;fri/20221209&lt;/p&gt;</td>\n",
       "      <td>fri/20221209</td>\n",
       "      <td>0.160710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 06:23:15</th>\n",
       "      <td>109482278888205908</td>\n",
       "      <td>&lt;p&gt;Being an insulin-injecting diabetic means o...</td>\n",
       "      <td>Being an insulin-injecting diabetic means occa...</td>\n",
       "      <td>-0.223550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-08 23:16:32</th>\n",
       "      <td>109480601078091132</td>\n",
       "      <td>&lt;p&gt;I am now part cyborg and have sent my first...</td>\n",
       "      <td>I am now part cyborg and have sent my first in...</td>\n",
       "      <td>-0.073293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-09 20:09:41  109485528680726575   \n",
       "2022-12-09 14:52:21  109484280827598555   \n",
       "2022-12-09 10:31:24  109483255136181443   \n",
       "2022-12-09 06:23:15  109482278888205908   \n",
       "2022-12-08 23:16:32  109480601078091132   \n",
       "\n",
       "                                                               Content  \\\n",
       "Date                                                                     \n",
       "2022-12-09 20:09:41  <p>Henceforth my insulin pump shall be known a...   \n",
       "2022-12-09 14:52:21                                                      \n",
       "2022-12-09 10:31:24                                <p>fri/20221209</p>   \n",
       "2022-12-09 06:23:15  <p>Being an insulin-injecting diabetic means o...   \n",
       "2022-12-08 23:16:32  <p>I am now part cyborg and have sent my first...   \n",
       "\n",
       "                                                                  Text  \\\n",
       "Date                                                                     \n",
       "2022-12-09 20:09:41  Henceforth my insulin pump shall be known as H...   \n",
       "2022-12-09 14:52:21                                                      \n",
       "2022-12-09 10:31:24                                       fri/20221209   \n",
       "2022-12-09 06:23:15  Being an insulin-injecting diabetic means occa...   \n",
       "2022-12-08 23:16:32  I am now part cyborg and have sent my first in...   \n",
       "\n",
       "                     BERT sentiment score  \n",
       "Date                                       \n",
       "2022-12-09 20:09:41              0.184103  \n",
       "2022-12-09 14:52:21              0.014581  \n",
       "2022-12-09 10:31:24              0.160710  \n",
       "2022-12-09 06:23:15             -0.223550  \n",
       "2022-12-08 23:16:32             -0.073293  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "list_predicted_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in insulin_dataloader:\n",
    "        input_ids, attention_mask = batch\n",
    "        output = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predicted_scores = output.logits.view(-1)\n",
    "\n",
    "        list_predicted_scores.extend(predicted_scores.tolist())\n",
    "\n",
    "df_insulin['BERT sentiment score'] = list_predicted_scores\n",
    "\n",
    "df_insulin.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../datasets/bert-scored/insulin.pkl', 'wb') as file:\n",
    "    pickle.dump(df_insulin, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis of the topic: Diabetes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataset with toots related to the topics 'Diabetes' and 'Diabetic'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-09 21:27:06</th>\n",
       "      <td>109485832811563069</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://masto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 20:34:47</th>\n",
       "      <td>109485626981509382</td>\n",
       "      <td>&lt;p&gt;Well. Libre 3 continues to be out of stock....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 20:12:11</th>\n",
       "      <td>109485538252881272</td>\n",
       "      <td>&lt;p&gt;As a T2 diabetic, I'm not supposed to eat b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 14:39:36</th>\n",
       "      <td>109484230932150244</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://hachy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 06:23:15</th>\n",
       "      <td>109482278888205908</td>\n",
       "      <td>&lt;p&gt;Being an insulin-injecting diabetic means o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-09 21:27:06  109485832811563069   \n",
       "2022-12-09 20:34:47  109485626981509382   \n",
       "2022-12-09 20:12:11  109485538252881272   \n",
       "2022-12-09 14:39:36  109484230932150244   \n",
       "2022-12-09 06:23:15  109482278888205908   \n",
       "\n",
       "                                                               Content  \n",
       "Date                                                                    \n",
       "2022-12-09 21:27:06  <p><span class=\"h-card\"><a href=\"https://masto...  \n",
       "2022-12-09 20:34:47  <p>Well. Libre 3 continues to be out of stock....  \n",
       "2022-12-09 20:12:11  <p>As a T2 diabetic, I'm not supposed to eat b...  \n",
       "2022-12-09 14:39:36  <p><span class=\"h-card\"><a href=\"https://hachy...  \n",
       "2022-12-09 06:23:15  <p>Being an insulin-injecting diabetic means o...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_diabetes = pd.DataFrame(columns=['Date','ID','Content'])\n",
    "diabetes_topics = ['Diabetes', 'Diabetic']\n",
    "\n",
    "for topic in diabetes_topics:\n",
    "    df_diabetes = pd.concat([df_diabetes,mastodon_dataframes[topic]])\n",
    "\n",
    "df_diabetes.drop_duplicates(subset='ID',keep='first',inplace=True)\n",
    "df_diabetes = df_diabetes.set_index('Date')\n",
    "\n",
    "df_diabetes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><span class=\"h-card\"><a href=\"https://mastodon.nz/@CaseyL\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>CaseyL</span></a></span> <br>I\\'m T2 with insulin, currently in the care of a specialised DHB diabetic team and extremely grateful to them. They\\'re stabilising my blood sugars. </p><p>I avoid sugar wherever possible, but my personal weakness is sticky buns. Just once in a blue moon... when nobody is looking ... </p><p>I do eat a lot of bread, pasta, &amp; potatoes and my dietician hasn\\'t asked me to cut down on those. Not yet anyway. </p><p><a href=\"https://mastodon.nz/tags/diabetes\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>diabetes</span></a> <a href=\"https://mastodon.nz/tags/diet\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>diet</span></a></p>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diabetes['Content'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that cleans the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CaseyL I'm T2 with insulin, currently in the care of a specialised DHB diabetic team and extremely grateful to them. They're stabilising my blood sugars. I avoid sugar wherever possible, but my personal weakness is sticky buns. Just once in a blue moon... when nobody is looking ... I do eat a lot of bread, pasta, & potatoes and my dietician hasn't asked me to cut down on those. Not yet anyway. diabetes diet\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[#@]', '', text)\n",
    "    return text\n",
    "\n",
    "df_diabetes['Text'] = df_diabetes['Content'].apply(clean_text)\n",
    "\n",
    "df_diabetes['Text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the cleaned text to the language BERT can interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "diabetes_encodings = tokenizer(df_diabetes['Text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "diabetes = torch.utils.data.TensorDataset(diabetes_encodings['input_ids'], diabetes_encodings['attention_mask'])\n",
    "diabetes_dataloader = DataLoader(diabetes, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading BERT that is trained on the normalized IMDB dataset from Stanford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = torch.load('bert-imdb.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BERT to perform sentiment analysis on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Text</th>\n",
       "      <th>BERT sentiment score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-09 21:27:06</th>\n",
       "      <td>109485832811563069</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://masto...</td>\n",
       "      <td>CaseyL I'm T2 with insulin, currently in the c...</td>\n",
       "      <td>-0.076328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 20:34:47</th>\n",
       "      <td>109485626981509382</td>\n",
       "      <td>&lt;p&gt;Well. Libre 3 continues to be out of stock....</td>\n",
       "      <td>Well. Libre 3 continues to be out of stock. So...</td>\n",
       "      <td>-0.443311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 20:12:11</th>\n",
       "      <td>109485538252881272</td>\n",
       "      <td>&lt;p&gt;As a T2 diabetic, I'm not supposed to eat b...</td>\n",
       "      <td>As a T2 diabetic, I'm not supposed to eat brea...</td>\n",
       "      <td>0.332407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 14:39:36</th>\n",
       "      <td>109484230932150244</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://hachy...</td>\n",
       "      <td>shanselman you might dig this. a local artist ...</td>\n",
       "      <td>0.208667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 06:23:15</th>\n",
       "      <td>109482278888205908</td>\n",
       "      <td>&lt;p&gt;Being an insulin-injecting diabetic means o...</td>\n",
       "      <td>Being an insulin-injecting diabetic means occa...</td>\n",
       "      <td>-0.223550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-09 21:27:06  109485832811563069   \n",
       "2022-12-09 20:34:47  109485626981509382   \n",
       "2022-12-09 20:12:11  109485538252881272   \n",
       "2022-12-09 14:39:36  109484230932150244   \n",
       "2022-12-09 06:23:15  109482278888205908   \n",
       "\n",
       "                                                               Content  \\\n",
       "Date                                                                     \n",
       "2022-12-09 21:27:06  <p><span class=\"h-card\"><a href=\"https://masto...   \n",
       "2022-12-09 20:34:47  <p>Well. Libre 3 continues to be out of stock....   \n",
       "2022-12-09 20:12:11  <p>As a T2 diabetic, I'm not supposed to eat b...   \n",
       "2022-12-09 14:39:36  <p><span class=\"h-card\"><a href=\"https://hachy...   \n",
       "2022-12-09 06:23:15  <p>Being an insulin-injecting diabetic means o...   \n",
       "\n",
       "                                                                  Text  \\\n",
       "Date                                                                     \n",
       "2022-12-09 21:27:06  CaseyL I'm T2 with insulin, currently in the c...   \n",
       "2022-12-09 20:34:47  Well. Libre 3 continues to be out of stock. So...   \n",
       "2022-12-09 20:12:11  As a T2 diabetic, I'm not supposed to eat brea...   \n",
       "2022-12-09 14:39:36  shanselman you might dig this. a local artist ...   \n",
       "2022-12-09 06:23:15  Being an insulin-injecting diabetic means occa...   \n",
       "\n",
       "                     BERT sentiment score  \n",
       "Date                                       \n",
       "2022-12-09 21:27:06             -0.076328  \n",
       "2022-12-09 20:34:47             -0.443311  \n",
       "2022-12-09 20:12:11              0.332407  \n",
       "2022-12-09 14:39:36              0.208667  \n",
       "2022-12-09 06:23:15             -0.223550  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "list_predicted_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in diabetes_dataloader:\n",
    "        input_ids, attention_mask = batch\n",
    "        output = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predicted_scores = output.logits.view(-1)\n",
    "\n",
    "        list_predicted_scores.extend(predicted_scores.tolist())\n",
    "\n",
    "df_diabetes['BERT sentiment score'] = list_predicted_scores\n",
    "\n",
    "df_diabetes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../datasets/bert-scored/diabetes.pkl', 'wb') as file:\n",
    "    pickle.dump(df_diabetes, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis of the topic: Pharmaceutic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataset with toots related to the topics 'pharmaceutical'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-06 19:03:34</th>\n",
       "      <td>109468281661273330</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://journ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06 18:45:15</th>\n",
       "      <td>109468210180810176</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://mstdn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06 14:32:45</th>\n",
       "      <td>109467216700022257</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://masto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06 11:12:06</th>\n",
       "      <td>109466427550668917</td>\n",
       "      <td>&lt;p&gt;Right.  I see when one types \"lft\" into the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-05 15:14:17</th>\n",
       "      <td>109461717496931207</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\" translate=\"no\"&gt;&lt;a href...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-06 19:03:34  109468281661273330   \n",
       "2022-12-06 18:45:15  109468210180810176   \n",
       "2022-12-06 14:32:45  109467216700022257   \n",
       "2022-12-06 11:12:06  109466427550668917   \n",
       "2022-12-05 15:14:17  109461717496931207   \n",
       "\n",
       "                                                               Content  \n",
       "Date                                                                    \n",
       "2022-12-06 19:03:34  <p><span class=\"h-card\"><a href=\"https://journ...  \n",
       "2022-12-06 18:45:15  <p><span class=\"h-card\"><a href=\"https://mstdn...  \n",
       "2022-12-06 14:32:45  <p><span class=\"h-card\"><a href=\"https://masto...  \n",
       "2022-12-06 11:12:06  <p>Right.  I see when one types \"lft\" into the...  \n",
       "2022-12-05 15:14:17  <p><span class=\"h-card\" translate=\"no\"><a href...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pharmaceutic = mastodon_dataframes['pharmaceutical']\n",
    "df_pharmaceutic = df_pharmaceutic.set_index('Date')\n",
    "\n",
    "df_pharmaceutic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pharmaceutic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><span class=\"h-card\"><a href=\"https://journa.host/@froomkin\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>froomkin</span></a></span> I have heard that Wikipedia rules constrain edits on pharmaceuticals to people who work for the big pharma companies and exclude various (e.g Stanford medicine) researchers.  That\\'s hearsay, but I kinda trust the source.</p>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pharmaceutic['Content'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that cleans the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"froomkin I have heard that Wikipedia rules constrain edits on pharmaceuticals to people who work for the big pharma companies and exclude various (e.g Stanford medicine) researchers.  That's hearsay, but I kinda trust the source.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[#@]', '', text)\n",
    "    return text\n",
    "\n",
    "df_pharmaceutic['Text'] = df_pharmaceutic['Content'].apply(clean_text)\n",
    "\n",
    "df_pharmaceutic['Text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the cleaned text to the language BERT can interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "pharmaceutic_encodings = tokenizer(df_pharmaceutic['Text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "pharmaceutic = torch.utils.data.TensorDataset(pharmaceutic_encodings['input_ids'], pharmaceutic_encodings['attention_mask'])\n",
    "pharmaceutic_dataloader = DataLoader(pharmaceutic, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading BERT that is trained on the normalized IMDB dataset from Stanford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = torch.load('bert-imdb.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BERT to perform sentiment analysis on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Text</th>\n",
       "      <th>BERT sentiment score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-06 19:03:34</th>\n",
       "      <td>109468281661273330</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://journ...</td>\n",
       "      <td>froomkin I have heard that Wikipedia rules con...</td>\n",
       "      <td>-0.360652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06 18:45:15</th>\n",
       "      <td>109468210180810176</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://mstdn...</td>\n",
       "      <td>Trapd The feds are reforming all of this right...</td>\n",
       "      <td>-0.181085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06 14:32:45</th>\n",
       "      <td>109467216700022257</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://masto...</td>\n",
       "      <td>BethanyBlack protip: citric acid.the super fan...</td>\n",
       "      <td>0.095077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06 11:12:06</th>\n",
       "      <td>109466427550668917</td>\n",
       "      <td>&lt;p&gt;Right.  I see when one types \"lft\" into the...</td>\n",
       "      <td>Right.  I see when one types \"lft\" into the se...</td>\n",
       "      <td>0.088579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-05 15:14:17</th>\n",
       "      <td>109461717496931207</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\" translate=\"no\"&gt;&lt;a href...</td>\n",
       "      <td>mattgemmell  one of the most baffling things a...</td>\n",
       "      <td>-0.309340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-06 19:03:34  109468281661273330   \n",
       "2022-12-06 18:45:15  109468210180810176   \n",
       "2022-12-06 14:32:45  109467216700022257   \n",
       "2022-12-06 11:12:06  109466427550668917   \n",
       "2022-12-05 15:14:17  109461717496931207   \n",
       "\n",
       "                                                               Content  \\\n",
       "Date                                                                     \n",
       "2022-12-06 19:03:34  <p><span class=\"h-card\"><a href=\"https://journ...   \n",
       "2022-12-06 18:45:15  <p><span class=\"h-card\"><a href=\"https://mstdn...   \n",
       "2022-12-06 14:32:45  <p><span class=\"h-card\"><a href=\"https://masto...   \n",
       "2022-12-06 11:12:06  <p>Right.  I see when one types \"lft\" into the...   \n",
       "2022-12-05 15:14:17  <p><span class=\"h-card\" translate=\"no\"><a href...   \n",
       "\n",
       "                                                                  Text  \\\n",
       "Date                                                                     \n",
       "2022-12-06 19:03:34  froomkin I have heard that Wikipedia rules con...   \n",
       "2022-12-06 18:45:15  Trapd The feds are reforming all of this right...   \n",
       "2022-12-06 14:32:45  BethanyBlack protip: citric acid.the super fan...   \n",
       "2022-12-06 11:12:06  Right.  I see when one types \"lft\" into the se...   \n",
       "2022-12-05 15:14:17  mattgemmell  one of the most baffling things a...   \n",
       "\n",
       "                     BERT sentiment score  \n",
       "Date                                       \n",
       "2022-12-06 19:03:34             -0.360652  \n",
       "2022-12-06 18:45:15             -0.181085  \n",
       "2022-12-06 14:32:45              0.095077  \n",
       "2022-12-06 11:12:06              0.088579  \n",
       "2022-12-05 15:14:17             -0.309340  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "list_predicted_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in pharmaceutic_dataloader:\n",
    "        input_ids, attention_mask = batch\n",
    "        output = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predicted_scores = output.logits.view(-1)\n",
    "\n",
    "        list_predicted_scores.extend(predicted_scores.tolist())\n",
    "\n",
    "df_pharmaceutic['BERT sentiment score'] = list_predicted_scores\n",
    "\n",
    "df_pharmaceutic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../datasets/bert-scored/pharmaceutic.pkl', 'wb') as file:\n",
    "    pickle.dump(df_pharmaceutic, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis of the topic: Medicine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataset with toots related to the topics 'Medicine' and 'Medical'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-10 19:59:30</th>\n",
       "      <td>109491150555807416</td>\n",
       "      <td>&lt;p&gt;This little two minute ambient piece has me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-10 19:44:30</th>\n",
       "      <td>109491093337726131</td>\n",
       "      <td>&lt;p&gt;How holiday spots are stocking up for our l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-10 18:59:22</th>\n",
       "      <td>109490914103968349</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\" translate=\"no\"&gt;&lt;a href...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-10 18:15:32</th>\n",
       "      <td>109490742076711264</td>\n",
       "      <td>&lt;p&gt;So I spent yesterday/last night in the ER.&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-10 17:44:08</th>\n",
       "      <td>109490618610928554</td>\n",
       "      <td>&lt;p&gt;Hmm, there are at least 3 people on our sma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-10 19:59:30  109491150555807416   \n",
       "2022-12-10 19:44:30  109491093337726131   \n",
       "2022-12-10 18:59:22  109490914103968349   \n",
       "2022-12-10 18:15:32  109490742076711264   \n",
       "2022-12-10 17:44:08  109490618610928554   \n",
       "\n",
       "                                                               Content  \n",
       "Date                                                                    \n",
       "2022-12-10 19:59:30  <p>This little two minute ambient piece has me...  \n",
       "2022-12-10 19:44:30  <p>How holiday spots are stocking up for our l...  \n",
       "2022-12-10 18:59:22  <p><span class=\"h-card\" translate=\"no\"><a href...  \n",
       "2022-12-10 18:15:32  <p>So I spent yesterday/last night in the ER.<...  \n",
       "2022-12-10 17:44:08  <p>Hmm, there are at least 3 people on our sma...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_medical = pd.DataFrame(columns=['Date','ID','Content'])\n",
    "medical_topics = ['Medicine', 'Medical']\n",
    "\n",
    "for topic in medical_topics:\n",
    "    df_medical = pd.concat([df_medical,mastodon_dataframes[topic]])\n",
    "\n",
    "df_medical.drop_duplicates(subset='ID',keep='first',inplace=True)\n",
    "df_medical = df_medical.set_index('Date')\n",
    "\n",
    "df_medical.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_medical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>This little two minute ambient piece has me hooked and wishing for a longer version! Can anyone suggest some more tracks in a similar style? I’m in love with the chord changes that take the music places. <a href=\"https://fosstodon.org/tags/music\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>music</span></a> <a href=\"https://fosstodon.org/tags/ambient\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ambient</span></a> <a href=\"https://music.apple.com/us/album/relajacion-medicinal/1593745101?i=1593745103\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">music.apple.com/us/album/relaj</span><span class=\"invisible\">acion-medicinal/1593745101?i=1593745103</span></a></p>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medical['Content'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that cleans the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This little two minute ambient piece has me hooked and wishing for a longer version! Can anyone suggest some more tracks in a similar style? I’m in love with the chord changes that take the music places. music ambient '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[#@]', '', text)\n",
    "    return text\n",
    "\n",
    "df_medical['Text'] = df_medical['Content'].apply(clean_text)\n",
    "\n",
    "df_medical['Text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the cleaned text to the language BERT can interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "medical_encodings = tokenizer(df_medical['Text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "medical = torch.utils.data.TensorDataset(medical_encodings['input_ids'], medical_encodings['attention_mask'])\n",
    "medical_dataloader = DataLoader(medical, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading BERT that is trained on the normalized IMDB dataset from Stanford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = torch.load('bert-imdb.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BERT to perform sentiment analysis on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Text</th>\n",
       "      <th>BERT sentiment score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-10 19:59:30</th>\n",
       "      <td>109491150555807416</td>\n",
       "      <td>&lt;p&gt;This little two minute ambient piece has me...</td>\n",
       "      <td>This little two minute ambient piece has me ho...</td>\n",
       "      <td>0.415996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-10 19:44:30</th>\n",
       "      <td>109491093337726131</td>\n",
       "      <td>&lt;p&gt;How holiday spots are stocking up for our l...</td>\n",
       "      <td>How holiday spots are stocking up for our late...</td>\n",
       "      <td>0.209835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-10 18:59:22</th>\n",
       "      <td>109490914103968349</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\" translate=\"no\"&gt;&lt;a href...</td>\n",
       "      <td>Erin absolutely. when I worked in the grooming...</td>\n",
       "      <td>-0.479018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-10 18:15:32</th>\n",
       "      <td>109490742076711264</td>\n",
       "      <td>&lt;p&gt;So I spent yesterday/last night in the ER.&lt;...</td>\n",
       "      <td>So I spent yesterday/last night in the ER.I wa...</td>\n",
       "      <td>-0.620889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-10 17:44:08</th>\n",
       "      <td>109490618610928554</td>\n",
       "      <td>&lt;p&gt;Hmm, there are at least 3 people on our sma...</td>\n",
       "      <td>Hmm, there are at least 3 people on our small ...</td>\n",
       "      <td>-0.508928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "Date                                      \n",
       "2022-12-10 19:59:30  109491150555807416   \n",
       "2022-12-10 19:44:30  109491093337726131   \n",
       "2022-12-10 18:59:22  109490914103968349   \n",
       "2022-12-10 18:15:32  109490742076711264   \n",
       "2022-12-10 17:44:08  109490618610928554   \n",
       "\n",
       "                                                               Content  \\\n",
       "Date                                                                     \n",
       "2022-12-10 19:59:30  <p>This little two minute ambient piece has me...   \n",
       "2022-12-10 19:44:30  <p>How holiday spots are stocking up for our l...   \n",
       "2022-12-10 18:59:22  <p><span class=\"h-card\" translate=\"no\"><a href...   \n",
       "2022-12-10 18:15:32  <p>So I spent yesterday/last night in the ER.<...   \n",
       "2022-12-10 17:44:08  <p>Hmm, there are at least 3 people on our sma...   \n",
       "\n",
       "                                                                  Text  \\\n",
       "Date                                                                     \n",
       "2022-12-10 19:59:30  This little two minute ambient piece has me ho...   \n",
       "2022-12-10 19:44:30  How holiday spots are stocking up for our late...   \n",
       "2022-12-10 18:59:22  Erin absolutely. when I worked in the grooming...   \n",
       "2022-12-10 18:15:32  So I spent yesterday/last night in the ER.I wa...   \n",
       "2022-12-10 17:44:08  Hmm, there are at least 3 people on our small ...   \n",
       "\n",
       "                     BERT sentiment score  \n",
       "Date                                       \n",
       "2022-12-10 19:59:30              0.415996  \n",
       "2022-12-10 19:44:30              0.209835  \n",
       "2022-12-10 18:59:22             -0.479018  \n",
       "2022-12-10 18:15:32             -0.620889  \n",
       "2022-12-10 17:44:08             -0.508928  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "list_predicted_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in medical_dataloader:\n",
    "        input_ids, attention_mask = batch\n",
    "        output = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predicted_scores = output.logits.view(-1)\n",
    "\n",
    "        list_predicted_scores.extend(predicted_scores.tolist())\n",
    "\n",
    "df_medical['BERT sentiment score'] = list_predicted_scores\n",
    "\n",
    "df_medical.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../datasets/bert-scored/medical.pkl', 'wb') as file:\n",
    "    pickle.dump(df_medical, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c75c0fdd1a718867cdcb84b32adcfdbeaad00b3a4e00a59385211aeed084d4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
