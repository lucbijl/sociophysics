{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion analysis with BERT\n",
    "\n",
    "Using transformers with the distilled bert-base model on the go-emotions dataset, to perform emotion analysis based on the circumplex model.\n",
    "\n",
    "Written by Luc Bijl."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the go-emotions training and testing dataset from the datasets directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "                                                Text Label       ID\n",
      "0  My favourite food is anything I didn't have to...    27  eebbqej\n",
      "1  Now if he does off himself, everyone will thin...    27  ed00q6i\n",
      "2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj\n",
      "3                        To make her feel threatened    14  ed7ypvh\n",
      "4                             Dirty Southern Wankers     3  ed0bdzj\n",
      "\n",
      "Test Data:\n",
      "                                                Text Label       ID\n",
      "0  I’m really sorry about your situation :( Altho...    25  eecwqtt\n",
      "1    It's wonderful because it's awful. At not with.     0  ed5f85d\n",
      "2  Kings fan here, good luck to you guys! Will be...    13  een27c3\n",
      "3  I didn't know that, thank you for teaching me ...    15  eelgwd1\n",
      "4  They got bored from haunting earth for thousan...    27  eem5uti\n",
      "\n",
      "Labels\n",
      "        Label     V     A     D\n",
      "0  admiration  0.80  0.50  0.70\n",
      "1   amusement  0.70  0.80  0.50\n",
      "2       anger -0.43  0.67  0.34\n",
      "3   annoyance -0.60  0.60  0.50\n",
      "4    approval  0.70  0.50  0.60\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "go_emotions_train_dataset = \"../../datasets/go-emotions/train.tsv\"\n",
    "go_emotions_test_dataset = \"../../datasets/go-emotions/test.tsv\"\n",
    "go_emotions_labels = \"../../datasets/go-emotions/emotions-labeled.csv\"\n",
    "\n",
    "column_names = ['Text', 'Label', 'ID']\n",
    "\n",
    "df_train_raw = pd.read_csv(go_emotions_train_dataset, delimiter='\\t', header=None, names=column_names)\n",
    "df_test_raw = pd.read_csv(go_emotions_test_dataset, delimiter='\\t', header=None, names=column_names)\n",
    "df_labels = pd.read_csv(go_emotions_labels, header=0, names=['Label', 'V', 'A', 'D'])\n",
    "\n",
    "print(\"Train Data:\")\n",
    "print(df_train_raw.head())\n",
    "print(\"\\nTest Data:\")\n",
    "print(df_test_raw.head())\n",
    "print(\"\\nLabels\")\n",
    "print(df_labels.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the labels in the training and testing dataset to the circumplex model with valence, arousal and dominance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mapping_train = []\n",
    "mapping_test = []\n",
    "\n",
    "df_train = df_train_raw[['Text']].copy()\n",
    "df_test = df_test_raw[['Text']].copy()\n",
    "\n",
    "for index, row in df_train_raw.iterrows():\n",
    "    matrix = []\n",
    "    labels = [int(label) for label in row['Label'].split(',')]\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix.extend([list(df_labels.loc[label][['V', 'A', 'D']])])\n",
    "    \n",
    "    mapping_train.extend([np.dot(np.array(matrix).reshape(3, len(labels)), np.ones(len(labels))) / len(labels)])\n",
    "\n",
    "df_train[['V', 'A', 'D']] = mapping_train\n",
    "\n",
    "for index, row in df_test_raw.iterrows():\n",
    "    matrix = []\n",
    "    labels = [int(label) for label in row['Label'].split(',')]\n",
    "    \n",
    "    for label in labels:\n",
    "        matrix.extend([list(df_labels.loc[label][['V', 'A', 'D']])])\n",
    "    \n",
    "    mapping_test.extend([np.dot(np.array(matrix).reshape(3, len(labels)), np.ones(len(labels))) / len(labels)])\n",
    "\n",
    "df_test[['V', 'A', 'D']] = mapping_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the summary statistics of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43410.000000</td>\n",
       "      <td>43410.000000</td>\n",
       "      <td>43410.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.208837</td>\n",
       "      <td>0.322031</td>\n",
       "      <td>0.204614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.493538</td>\n",
       "      <td>0.325608</td>\n",
       "      <td>0.314346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.665000</td>\n",
       "      <td>-0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  V             A             D\n",
       "count  43410.000000  43410.000000  43410.000000\n",
       "mean       0.208837      0.322031      0.204614\n",
       "std        0.493538      0.325608      0.314346\n",
       "min       -0.700000     -0.665000     -0.700000\n",
       "25%        0.000000      0.000000      0.000000\n",
       "50%        0.000000      0.400000      0.200000\n",
       "75%        0.700000      0.550000      0.500000\n",
       "max        0.900000      0.900000      0.800000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['V', 'A', 'D']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the most extreme sentences in the training set in either of the three dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min V:\n",
      "Text    He was off by 5 minutes, not impressed. \n",
      "V                                           -0.7\n",
      "A                                            0.5\n",
      "D                                           -0.6\n",
      "Name: 87, dtype: object\n",
      "\n",
      "Max V:\n",
      "Text    Very interesting. Thx\n",
      "V                         0.9\n",
      "A                         0.7\n",
      "D                         0.4\n",
      "Name: 54, dtype: object\n",
      "\n",
      "\n",
      "Min A:\n",
      "Text    I wasn't meaning it as an insult or anything, ...\n",
      "V                                                    -0.2\n",
      "A                                                  -0.665\n",
      "D                                                   -0.03\n",
      "Name: 399, dtype: object\n",
      "\n",
      "Max A:\n",
      "Text    This...has 9k upvotes. Wow.\n",
      "V                               0.9\n",
      "A                               0.9\n",
      "D                               0.6\n",
      "Name: 63, dtype: object\n",
      "\n",
      "\n",
      "Min D:\n",
      "Text    Apologies, I take it all back as I’ve just see...\n",
      "V                                                    -0.6\n",
      "A                                                     0.2\n",
      "D                                                    -0.7\n",
      "Name: 92, dtype: object\n",
      "\n",
      "Max D:\n",
      "Text    Sounds like a horror junkie in the making. Con...\n",
      "V                                                0.666667\n",
      "A                                                0.666667\n",
      "D                                                     0.8\n",
      "Name: 11327, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['V','A','D']:\n",
    "    print(\"Min {}:\\n{}\".format(i, df_train.loc[df_train[i].argmin()]))\n",
    "    print()\n",
    "    print(\"Max {}:\\n{}\".format(i, df_train.loc[df_train[i].argmax()]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min V:\n",
      "Text    Crap. I need more Excedrin. STAT.\n",
      "V                                    -0.7\n",
      "A                                     0.5\n",
      "D                                    -0.6\n",
      "Name: 68, dtype: object\n",
      "\n",
      "Max V:\n",
      "Text    Kings fan here, good luck to you guys! Will be...\n",
      "V                                                     0.9\n",
      "A                                                     0.9\n",
      "D                                                     0.6\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "Min A:\n",
      "Text    And [NAME], would again like to apologize for ...\n",
      "V                                                    -0.2\n",
      "A                                                  -0.665\n",
      "D                                                   -0.03\n",
      "Name: 182, dtype: object\n",
      "\n",
      "Max A:\n",
      "Text    Kings fan here, good luck to you guys! Will be...\n",
      "V                                                     0.9\n",
      "A                                                     0.9\n",
      "D                                                     0.6\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "Min D:\n",
      "Text    I’m sorry to hear that friend :(. It’s for the...\n",
      "V                                                    -0.6\n",
      "A                                                     0.2\n",
      "D                                                    -0.7\n",
      "Name: 8, dtype: object\n",
      "\n",
      "Max D:\n",
      "Text    What a finish\n",
      "V                0.65\n",
      "A                 0.8\n",
      "D                0.75\n",
      "Name: 833, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['V','A','D']:\n",
    "    print(\"Min {}:\\n{}\".format(i, df_test.loc[df_test[i].argmin()]))\n",
    "    print()\n",
    "    print(\"Max {}:\\n{}\".format(i, df_test.loc[df_test[i].argmax()]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the length of the training and testing dataset, to set a proper batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length training set: 43410\n",
      "Length testing set: 5427\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length training set: {len(df_train)}\\nLength testing set: {len(df_test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data for BERT, this includes tokenization, encoding and creating dataloaders for both training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luc/packages/anaconda/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "# Tokenizing and encoding the text data\n",
    "train_encodings = tokenizer(df_train['Text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "test_encodings = tokenizer(df_test['Text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Creating data loaders\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    train_encodings['input_ids'], \n",
    "    train_encodings['attention_mask'], \n",
    "    torch.tensor(df_train[['V', 'A', 'D']].values, dtype=torch.float32)\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=30, shuffle=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    test_encodings['input_ids'], \n",
    "    test_encodings['attention_mask'], \n",
    "    torch.tensor(df_test[['V', 'A', 'D']].values, dtype=torch.float32)\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=27, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model: distilbert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import L1Loss\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = L1Loss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the training loop, here BERT will be trained with the training dataset and validated with the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Training Loss: 0.6840\n",
      "Epoch 1/30, Validation Loss: 0.6063\n",
      "\n",
      "Epoch 2/30, Training Loss: 0.5961\n",
      "Epoch 2/30, Validation Loss: 0.5880\n",
      "\n",
      "Epoch 3/30, Training Loss: 0.5556\n",
      "Epoch 3/30, Validation Loss: 0.5794\n",
      "\n",
      "Epoch 4/30, Training Loss: 0.5192\n",
      "Epoch 4/30, Validation Loss: 0.5826\n",
      "\n",
      "Epoch 5/30, Training Loss: 0.4942\n",
      "Epoch 5/30, Validation Loss: 0.5743\n",
      "\n",
      "Epoch 6/30, Training Loss: 0.4677\n",
      "Epoch 6/30, Validation Loss: 0.5806\n",
      "\n",
      "Epoch 7/30, Training Loss: 0.4501\n",
      "Epoch 7/30, Validation Loss: 0.5746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "log_dir = 'bert-go-emotion-1/logs'\n",
    "writer = SummaryWriter(log_dir)\n",
    "global_step = 0\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "early_stop_patience = 2\n",
    "best_validation_loss = float('inf')\n",
    "no_improvement_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_loss_v = 0\n",
    "    total_loss_a = 0\n",
    "    total_loss_d = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        global_step += 1\n",
    "        num_batches += 1\n",
    "        input_ids, attention_mask, target_scores = batch\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predicted_scores = output.logits\n",
    "\n",
    "        # Calculating the loss for each dimensions\n",
    "        loss_v = loss_fn(predicted_scores[:,0], target_scores[:,0])\n",
    "        loss_a = loss_fn(predicted_scores[:,1], target_scores[:,1])\n",
    "        loss_d = loss_fn(predicted_scores[:,2], target_scores[:,2])\n",
    "\n",
    "        # The main loss is defined as the sum of the individual losses\n",
    "        loss = loss_v + loss_a + loss_d\n",
    "\n",
    "        # The total loss per epoch\n",
    "        total_loss_v += loss_v.item()\n",
    "        total_loss_a += loss_a.item()\n",
    "        total_loss_d += loss_d.item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Determining the average loss in the epoch\n",
    "        average_loss_v = total_loss_v / num_batches\n",
    "        average_loss_a = total_loss_a / num_batches\n",
    "        average_loss_d = total_loss_d / num_batches\n",
    "        average_loss = total_loss / num_batches\n",
    "\n",
    "        # Tensorboard logging\n",
    "        writer.add_scalar('Batch-loss-train-valence', average_loss_v, global_step)\n",
    "        writer.add_scalar('Batch-loss-train-arousal', average_loss_a, global_step)\n",
    "        writer.add_scalar('Batch-loss-train-dominance', average_loss_d, global_step)\n",
    "        writer.add_scalar('Batch-loss-train', average_loss, global_step)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Determining the average loss for the epoch\n",
    "    average_loss_v = total_loss_v / len(train_dataloader)\n",
    "    average_loss_a = total_loss_a / len(train_dataloader)\n",
    "    average_loss_d = total_loss_d / len(train_dataloader)\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    # Logging\n",
    "    writer.add_scalar('Epoch-loss-train-valence', average_loss_v, epoch + 1)\n",
    "    writer.add_scalar('Epoch-loss-train-arousal', average_loss_a, epoch + 1)\n",
    "    writer.add_scalar('Epoch-loss-train-dominance', average_loss_d, epoch + 1)\n",
    "    writer.add_scalar('Epoch-loss-train', average_loss, epoch + 1)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_loss_v = 0\n",
    "    total_loss_a = 0\n",
    "    total_loss_d = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            input_ids, attention_mask, target_scores = batch\n",
    "\n",
    "            # Obtaining the scores\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predicted_scores = output.logits\n",
    "\n",
    "            # Calculating the loss for each dimensions\n",
    "            loss_v = loss_fn(predicted_scores[:,0], target_scores[:,0])\n",
    "            loss_a = loss_fn(predicted_scores[:,1], target_scores[:,1])\n",
    "            loss_d = loss_fn(predicted_scores[:,2], target_scores[:,2])\n",
    "            \n",
    "            # The main loss is defined as the sum of the individual losses\n",
    "            loss = loss_v + loss_a + loss_d\n",
    "\n",
    "            # The total loss per epoch\n",
    "            total_loss_v += loss_v.item()\n",
    "            total_loss_a += loss_a.item()\n",
    "            total_loss_d += loss_d.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    # Determining the average loss for the epoch\n",
    "    average_loss_v = total_loss_v / len(test_dataloader)\n",
    "    average_loss_a = total_loss_a / len(test_dataloader)\n",
    "    average_loss_d = total_loss_d / len(test_dataloader)\n",
    "    average_loss = total_loss / len(test_dataloader)\n",
    "\n",
    "    # Logging  \n",
    "    writer.add_scalar('Epoch-loss-validation-valence', average_loss_v, epoch + 1)\n",
    "    writer.add_scalar('Epoch-loss-validation-arousal', average_loss_a, epoch + 1)\n",
    "    writer.add_scalar('Epoch-loss-validation-dominance', average_loss_d, epoch + 1)\n",
    "    writer.add_scalar('Epoch-loss-validation', average_loss, epoch + 1)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {average_loss:.4f}\\n\")\n",
    "\n",
    "    # Saving the model\n",
    "    torch.save(model, f'bert-go-emotion-1/{epoch + 1}.pth')\n",
    "\n",
    "    # Early stopping check\n",
    "    if average_loss < best_validation_loss:\n",
    "        best_validation_loss = average_loss\n",
    "        no_improvement_counter = 0\n",
    "    else:\n",
    "        no_improvement_counter += 1\n",
    "\n",
    "    if no_improvement_counter >= early_stop_patience:\n",
    "        break\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('bert-go-emotion-1/7.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model, with as output the MAE, MSE and R-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient (R) V: 0.6871\n",
      "Mean Squared Error (MSE) V: 0.1450\n",
      "Mean Absolute Error (MAE) V: 0.2278\n",
      "\n",
      "Pearson Correlation Coefficient (R) A: 0.5471\n",
      "Mean Squared Error (MSE) A: 0.0838\n",
      "Mean Absolute Error (MAE) A: 0.1825\n",
      "\n",
      "Pearson Correlation Coefficient (R) D: 0.5982\n",
      "Mean Squared Error (MSE) D: 0.0696\n",
      "Mean Absolute Error (MAE) D: 0.1643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "model.eval()\n",
    "list_predicted_scores = {'V': [], 'A': [], 'D': []}\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        input_ids, attention_mask, target_scores = batch\n",
    "\n",
    "        # Obtaining the scores\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predicted_scores = output.logits\n",
    "\n",
    "        # Writing the scores to the list\n",
    "        list_predicted_scores['V'].extend(predicted_scores[:, 0].tolist())\n",
    "        list_predicted_scores['A'].extend(predicted_scores[:, 1].tolist())\n",
    "        list_predicted_scores['D'].extend(predicted_scores[:, 2].tolist())\n",
    "\n",
    "# Inserting the scores in df_test\n",
    "for i,j in zip(['V', 'A', 'D'],['V-p', 'A-p', 'D-p']):\n",
    "    df_test[j] = list_predicted_scores[i]\n",
    "\n",
    "# Computing the R, MSE and MAE values.\n",
    "for i,j in zip(['V', 'A', 'D'],['V-p', 'A-p', 'D-p']):\n",
    "\n",
    "    correlation, _ = pearsonr(df_test[i], df_test[j])\n",
    "\n",
    "    print(f\"Pearson Correlation Coefficient (R) {i}: {correlation:.4f}\")\n",
    "    print(f\"Mean Squared Error (MSE) {i}: {mean_squared_error(df_test[i], df_test[j]):.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE) {i}: {mean_absolute_error(df_test[i], df_test[j]):.4f}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the summary statistics of the testing dataset and the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>V-p</th>\n",
       "      <th>A</th>\n",
       "      <th>A-p</th>\n",
       "      <th>D</th>\n",
       "      <th>D-p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5427.000000</td>\n",
       "      <td>5427.000000</td>\n",
       "      <td>5427.000000</td>\n",
       "      <td>5427.000000</td>\n",
       "      <td>5427.000000</td>\n",
       "      <td>5427.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.199616</td>\n",
       "      <td>0.217029</td>\n",
       "      <td>0.317785</td>\n",
       "      <td>0.315409</td>\n",
       "      <td>0.204603</td>\n",
       "      <td>0.203345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497983</td>\n",
       "      <td>0.459614</td>\n",
       "      <td>0.320525</td>\n",
       "      <td>0.284040</td>\n",
       "      <td>0.313527</td>\n",
       "      <td>0.268033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.742525</td>\n",
       "      <td>-0.665000</td>\n",
       "      <td>-0.341613</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.634617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.395903</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.139291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.720704</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.521588</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.418724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.941922</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.938188</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V          V-p            A          A-p            D  \\\n",
       "count  5427.000000  5427.000000  5427.000000  5427.000000  5427.000000   \n",
       "mean      0.199616     0.217029     0.317785     0.315409     0.204603   \n",
       "std       0.497983     0.459614     0.320525     0.284040     0.313527   \n",
       "min      -0.700000    -0.742525    -0.665000    -0.341613    -0.700000   \n",
       "25%       0.000000     0.000007     0.000000     0.000012     0.000000   \n",
       "50%       0.000000     0.000998     0.400000     0.395903     0.200000   \n",
       "75%       0.700000     0.720704     0.500000     0.521588     0.500000   \n",
       "max       0.900000     0.941922     0.900000     0.938188     0.750000   \n",
       "\n",
       "               D-p  \n",
       "count  5427.000000  \n",
       "mean      0.203345  \n",
       "std       0.268033  \n",
       "min      -0.634617  \n",
       "25%      -0.000016  \n",
       "50%       0.139291  \n",
       "75%       0.418724  \n",
       "max       0.753028  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['V', 'V-p', 'A', 'A-p', 'D', 'D-p']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the most extreme sentences in the test set in either of the six dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min V:\n",
      "Text    Crap. I need more Excedrin. STAT.\n",
      "V                                    -0.7\n",
      "A                                     0.5\n",
      "D                                    -0.6\n",
      "V-p                             -0.238292\n",
      "A-p                              0.348867\n",
      "D-p                              0.091098\n",
      "Name: 68, dtype: object\n",
      "\n",
      "Max V:\n",
      "Text    Kings fan here, good luck to you guys! Will be...\n",
      "V                                                     0.9\n",
      "A                                                     0.9\n",
      "D                                                     0.6\n",
      "V-p                                              0.765529\n",
      "A-p                                              0.597058\n",
      "D-p                                              0.513681\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "Min V-p:\n",
      "Text    I'm a little disappointed that the tier markin...\n",
      "V                                                    -0.7\n",
      "A                                                     0.5\n",
      "D                                                    -0.6\n",
      "V-p                                             -0.742525\n",
      "A-p                                              0.626563\n",
      "D-p                                             -0.634617\n",
      "Name: 3107, dtype: object\n",
      "\n",
      "Max V-p:\n",
      "Text    I’m super excited and waiting for the FOV slid...\n",
      "V                                                     0.9\n",
      "A                                                     0.9\n",
      "D                                                     0.6\n",
      "V-p                                              0.941922\n",
      "A-p                                              0.901214\n",
      "D-p                                              0.602493\n",
      "Name: 5195, dtype: object\n",
      "\n",
      "\n",
      "Min A:\n",
      "Text    And [NAME], would again like to apologize for ...\n",
      "V                                                    -0.2\n",
      "A                                                  -0.665\n",
      "D                                                   -0.03\n",
      "V-p                                             -0.004741\n",
      "A-p                                              0.000905\n",
      "D-p                                             -0.003656\n",
      "Name: 182, dtype: object\n",
      "\n",
      "Max A:\n",
      "Text    Kings fan here, good luck to you guys! Will be...\n",
      "V                                                     0.9\n",
      "A                                                     0.9\n",
      "D                                                     0.6\n",
      "V-p                                              0.765529\n",
      "A-p                                              0.597058\n",
      "D-p                                              0.513681\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "Min A-p:\n",
      "Text    That doesn’t seem like very responsible presen...\n",
      "V                                                    -0.4\n",
      "A                                                    0.25\n",
      "D                                                     0.0\n",
      "V-p                                             -0.640455\n",
      "A-p                                             -0.341613\n",
      "D-p                                              0.519503\n",
      "Name: 4134, dtype: object\n",
      "\n",
      "Max A-p:\n",
      "Text    I love [NAME] already\n",
      "V                         0.7\n",
      "A                         0.9\n",
      "D                         0.4\n",
      "V-p                  0.710451\n",
      "A-p                  0.938188\n",
      "D-p                  0.397899\n",
      "Name: 1585, dtype: object\n",
      "\n",
      "\n",
      "Min D:\n",
      "Text    I’m sorry to hear that friend :(. It’s for the...\n",
      "V                                                    -0.6\n",
      "A                                                     0.2\n",
      "D                                                    -0.7\n",
      "V-p                                             -0.632151\n",
      "A-p                                              0.222603\n",
      "D-p                                             -0.496072\n",
      "Name: 8, dtype: object\n",
      "\n",
      "Max D:\n",
      "Text    What a finish\n",
      "V                0.65\n",
      "A                 0.8\n",
      "D                0.75\n",
      "V-p          0.772704\n",
      "A-p          0.495321\n",
      "D-p           0.65556\n",
      "Name: 833, dtype: object\n",
      "\n",
      "\n",
      "Min D-p:\n",
      "Text    I'm a little disappointed that the tier markin...\n",
      "V                                                    -0.7\n",
      "A                                                     0.5\n",
      "D                                                    -0.6\n",
      "V-p                                             -0.742525\n",
      "A-p                                              0.626563\n",
      "D-p                                             -0.634617\n",
      "Name: 3107, dtype: object\n",
      "\n",
      "Max D-p:\n",
      "Text    I'm on board the Saints hype train. [NAME] is ...\n",
      "V                                                     0.8\n",
      "A                                                     0.5\n",
      "D                                                     0.7\n",
      "V-p                                              0.820743\n",
      "A-p                                              0.509602\n",
      "D-p                                              0.753028\n",
      "Name: 110, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['V', 'V-p', 'A', 'A-p', 'D', 'D-p']:\n",
    "    print(\"Min {}:\\n{}\".format(i, df_test.loc[df_test[i].argmin()]))\n",
    "    print()\n",
    "    print(\"Max {}:\\n{}\".format(i, df_test.loc[df_test[i].argmax()]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c75c0fdd1a718867cdcb84b32adcfdbeaad00b3a4e00a59385211aeed084d4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
