{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with BERT\n",
    "\n",
    "Using transformers with the distilled bert-base model on the IMDB dataset, to perform continuous score sentiment analysis.\n",
    "\n",
    "Written by Luc Bijl."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving IMDB training and testing dataset from datasets directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "                                              Review  Sentiment\n",
      "0  In my opinion, the best movie ever. I love whe...         10\n",
      "1  I have seen The Running Man several times as I...          9\n",
      "2  actually... that \"video camera\" effect, is jus...          8\n",
      "3  The year 1995, when so many people talked abou...          9\n",
      "4  Bravo! Morgan Freeman is an actor, who researc...         10\n",
      "\n",
      "Test Data:\n",
      "                                              Review  Sentiment\n",
      "0  Alex North (John Cassavetes) has problems in r...          7\n",
      "1  I won't go to a generalization, and say it's t...         10\n",
      "2  Movie about two Australian girls--Debbie (Nell...          7\n",
      "3  A bland title disguises this solidly-carpenter...          7\n",
      "4  I was laying in bed, flicking through the chan...          8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_dataset = \"../../datasets/aciimdb/train\"\n",
    "test_dataset = \"../../datasets/aciimdb/test\"\n",
    "\n",
    "train_reviews = []\n",
    "train_scores = []\n",
    "test_reviews = []\n",
    "test_scores = []\n",
    "\n",
    "for dataset, reviews, scores in [(train_dataset, train_reviews, train_scores), (test_dataset, test_reviews, test_scores)]:\n",
    "    for sentiment in ['pos','neg']:\n",
    "        sentiment_dir = os.path.join(dataset,sentiment)\n",
    "\n",
    "        for filename in os.listdir(sentiment_dir):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(os.path.join(sentiment_dir,filename),'r',encoding='utf-8') as file:\n",
    "                    review = file.read()\n",
    "                    sentiment_score = int(filename[:-4].split('_')[1])\n",
    "\n",
    "                    scores.append(sentiment_score)\n",
    "                    reviews.append(review)\n",
    "\n",
    "train_data = {'Review': train_reviews, 'Sentiment': train_scores}\n",
    "test_data = {'Review': test_reviews, 'Sentiment': test_scores}\n",
    "\n",
    "df_train_data = pd.DataFrame(train_data)\n",
    "df_test_data = pd.DataFrame(test_data)\n",
    "\n",
    "print(\"Train Data:\")\n",
    "print(df_train_data.head())\n",
    "print(\"\\nTest Data:\")\n",
    "print(df_test_data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the training and testing dataset to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "                                              Review  Sentiment  \\\n",
      "0  In my opinion, the best movie ever. I love whe...         10   \n",
      "1  I have seen The Running Man several times as I...          9   \n",
      "2  actually... that \"video camera\" effect, is jus...          8   \n",
      "3  The year 1995, when so many people talked abou...          9   \n",
      "4  Bravo! Morgan Freeman is an actor, who researc...         10   \n",
      "\n",
      "   Normal sentiment  \n",
      "0               1.0  \n",
      "1               0.8  \n",
      "2               0.6  \n",
      "3               0.8  \n",
      "4               1.0  \n",
      "\n",
      "Test Data:\n",
      "                                              Review  Sentiment  \\\n",
      "0  Alex North (John Cassavetes) has problems in r...          7   \n",
      "1  I won't go to a generalization, and say it's t...         10   \n",
      "2  Movie about two Australian girls--Debbie (Nell...          7   \n",
      "3  A bland title disguises this solidly-carpenter...          7   \n",
      "4  I was laying in bed, flicking through the chan...          8   \n",
      "\n",
      "   Normal sentiment  \n",
      "0               0.4  \n",
      "1               1.0  \n",
      "2               0.4  \n",
      "3               0.4  \n",
      "4               0.6  \n"
     ]
    }
   ],
   "source": [
    "def normalize(n):\n",
    "    normal_n = (n - 5) / 5\n",
    "    return normal_n\n",
    "\n",
    "df_train_data['Normal sentiment'] = normalize(df_train_data['Sentiment'])\n",
    "df_test_data['Normal sentiment'] = normalize(df_test_data['Sentiment'])\n",
    "\n",
    "print(\"Train Data:\")\n",
    "print(df_train_data.head())\n",
    "print(\"\\nTest Data:\")\n",
    "print(df_test_data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a validation sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 500\n",
    "df_validation_data = df_test_data.sample(n=samples,random_state=42)\n",
    "df_validation_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data for BERT, this includes tokenization, encoding and creating dataloaders for both training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize and encode the text data\n",
    "train_encodings = tokenizer(df_train_data['Review'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "validation_encodings = tokenizer(df_validation_data['Review'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Create data loaders\n",
    "train = torch.utils.data.TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(df_train_data['Normal sentiment']))\n",
    "train_dataloader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "\n",
    "validation = torch.utils.data.TensorDataset(validation_encodings['input_ids'], validation_encodings['attention_mask'], torch.tensor(df_validation_data['Normal sentiment']))\n",
    "validation_dataloader = DataLoader(validation, batch_size=16, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model: BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(model_name,num_labels=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop. Here BERT will be trained with the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "log_dir = 'logs'\n",
    "writer = SummaryWriter(log_dir)\n",
    "global_step = 0\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        global_step += 1\n",
    "\n",
    "        input_ids, attention_mask, scores = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predicted_scores = output.logits.view(-1)\n",
    "\n",
    "        loss = loss_fn(predicted_scores, scores.float())\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar('Loss-train', loss, global_step)\n",
    "\n",
    "        model.eval()\n",
    "        validation_total_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch in validation_dataloader:\n",
    "            with torch.no_grad():\n",
    "                input_ids, attention_mask, scores = batch\n",
    "                output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                predicted_scores = output.logits.view(-1)\n",
    "\n",
    "                loss = loss_fn(predicted_scores, scores.float())\n",
    "                validation_total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "\n",
    "        if num_batches > 0:\n",
    "            validation_loss = validation_total_loss / num_batches\n",
    "        else:\n",
    "            validation_loss = 0.0   \n",
    "\n",
    "        writer.add_scalar('Loss-validation', validation_loss,global_step)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a testing sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 100\n",
    "df_test_sample = df_test_data.sample(n=samples,random_state=42)\n",
    "df_test_sample.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'bert-imdb.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../bert-imdb.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better method of evaluation. With as output the MAE, MSE and R-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.1785\n",
      "Mean Absolute Error (MAE): 0.2919\n",
      "Pearson Correlation Coefficient (R): 0.8217\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "test_encodings = tokenizer(df_test_sample['Review'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "test = torch.utils.data.TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(df_test_sample['Normal sentiment']))\n",
    "test_dataloader = DataLoader(test, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "total_ae = 0\n",
    "total_se = 0\n",
    "total_samples = 0\n",
    "list_predicted_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, scores = batch\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predicted_scores = output.logits.view(-1)\n",
    "\n",
    "        list_predicted_scores.extend(predicted_scores.tolist())\n",
    "\n",
    "        ae = torch.abs(predicted_scores - scores.float()).sum().item()\n",
    "        total_ae += ae\n",
    "\n",
    "        se = ((predicted_scores - scores.float()) ** 2).sum().item()\n",
    "        total_se += se\n",
    "\n",
    "        total_samples += scores.size(0)\n",
    "\n",
    "mse = total_se / total_samples\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "mae = total_ae / total_samples\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "df_test_sample['BERT sentiment'] = list_predicted_scores\n",
    "\n",
    "correlation, _ = pearsonr(df_test_sample['Normal sentiment'],df_test_sample['BERT sentiment'])\n",
    "print(f\"Pearson Correlation Coefficient (R): {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.1785\n",
      "Mean Absolute Error (MAE): 0.2919\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(df_test_sample['Normal sentiment'],df_test_sample['BERT sentiment']):.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(df_test_sample['Normal sentiment'],df_test_sample['BERT sentiment']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c75c0fdd1a718867cdcb84b32adcfdbeaad00b3a4e00a59385211aeed084d4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
